{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# CS677 Assign 11\n# by Zuowen Tang",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# ------------------------\n# SVM\n# ------------------------",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\n\n\ndef getData(year):\n    df = pd.read_csv('TMO_weekly_label.csv')\n    df = df[df['Year'] == year]\n    X = df[['Mean Return', 'Volatility']].values\n    Y = df['Label'].values\n    return X, Y\n\n\ndef getTable(cm, i):\n    TP = cm[i][0][0]\n    FP = cm[i][0][1]\n    FN = cm[i][1][0]\n    TN = cm[i][1][1]\n    TPR = TP / (TP + FN)\n    TNR = TN / (TN + FP)\n    ACC = (TP + TN) / (TP + TN + FP + FN)\n    d = {'Accuracy': [ACC], 'True positive rate': [TPR], 'True negative rate': [TNR]}\n    dfx = pd.DataFrame(data=d)\n    return dfx",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def SVM():\n    x_train, y_train = getData(2021)\n    x_test, y_test = getData(2022)\n    cm, prediction = [], []\n\n    # Task 1-5\n    for i in range(3):\n        if i == 0:\n            # 1-3. implement a linear SVM.\n            svm_classifier = svm.SVC(kernel='linear')\n            kern = 'linear'\n        elif i == 1:\n            # 4. implement a Gaussian SVM\n            svm_classifier = svm.SVC(kernel='rbf')\n            kern = 'Gaussian'\n        else:\n            # 5. implement polynomial SVM degree 2\n            svm_classifier = svm.SVC(kernel='poly', degree=2)\n            kern = 'polynomial'\n\n        svm_classifier.fit(x_train, y_train)\n        predicted = svm_classifier.predict(x_test)\n        accuracy = svm_classifier.score(x_test, y_test)\n        prediction.append(predicted)\n        cm.append(confusion_matrix(y_test, predicted))\n        dfx = getTable(cm, i)\n\n        print('\\nTask', i+1)\n        print('Implement a', kern, 'SVM:')\n        print('The accuracy is', accuracy)\n        print('The confusion matrix is:')\n        print(cm[i])\n        print(dfx)\n\n    # 6. implement a trading strategy based on your labels (from linear SVM) for year 2\n    # and compare the performance with the ”buy-and-hold” strategy.\n    # Which strategy results in a larger amount at the end of the year?\n    df2 = pd.read_csv(\"TMO_weekly_label.csv\")\n    df2 = df2[df2['Year'] == 2022]\n    meanReturn = df2['Mean Return']\n    print(\"\\nTask 4:\")\n    print('Money earned based on buy-and-hold strategy for Year2:')\n    print(\"-2.2672499999999984\")\n\n    for i in range(3):\n        if i == 0:\n            kern = 'linear'\n        elif i == 1:\n            kern = 'Gaussian'\n        else:\n            kern = 'polynomial'\n\n        meanReturn = list(df2['Mean Return'])\n        moneyEarned = 0\n        for j in range(52):\n            if prediction[i][j] == 'g':\n                moneyEarned = moneyEarned + meanReturn[j]\n        print('\\nNew strategy: only buy when the predicted label is green.')\n        print('Money earned based on', kern, 'SVM strategy for Year2:')\n        print(moneyEarned)\n\n    print('\\nStrategy based on linear SVM has the largest amount at the end of the year.')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "SVM()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# ------------------------\n# NB, Trees & RF\n# ------------------------",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom sklearn import svm\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef getData():\n    # Q1 data preparation\n    df = pd.read_excel('cardiotocography_data_set.xls', sheet_name=\"Raw Data\")\n    df[\"NSP\"] = np.where(df[\"NSP\"] < 2, 1, 0)\n    X = df[[\"ASTV\", \"MLTV\", \"Max\", \"Median\"]].values\n    Y = df[[\"NSP\"]].values\n    x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.5)\n    return x_train, x_test, y_train, y_test\n\n\ndef getTable(cm, i, all=False):\n    TP = cm[i][0][0]\n    FP = cm[i][0][1]\n    FN = cm[i][1][0]\n    TN = cm[i][1][1]\n    TPR = TP / (TP + FN)\n    TNR = TN / (TN + FP)\n    ACC = (TP + TN) / (TP + TN + FP + FN)\n    d = {'Accuracy': [ACC], 'True positive rate': [TPR], 'True negative rate': [TNR]}\n    dfx = pd.DataFrame(data=d)\n    if all:\n        return TP, FP, FN, TN, TPR, TNR, ACC\n    return dfx\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def Q2_Q7():\n    x_train, x_test, y_train, y_test = getData()\n    result_table = pd.DataFrame(columns=['Method', 'TP', 'FP', 'FN', 'TN', 'Accuracy', 'TPR', 'TNR'])\n    method = ['Naive Bayesian', 'Logistic Regression', 'Decision Tree', 'Random Forest',\n              'linear SVM', 'degree 2 SVM', 'Gaussian SVM']\n    cm = []\n\n    # 2. Use Naive Bayesian NB classifier\n    NB_classifier = GaussianNB().fit(x_train, y_train)\n    accuracy = accuracy_score(y_test, NB_classifier.predict(x_test))\n    cm.append(confusion_matrix(y_test, NB_classifier.predict(x_test)))\n    dfx = getTable(cm, 0)\n\n    print(\"\\nQ2:\")\n    print('Implement a Naive Bayesian classifier:')\n    print('The accuracy is', accuracy)\n    print(cm[0])\n    print(dfx)\n\n    # 3. Use Logistic regression classifier\n    log_reg_classifier = LogisticRegression()\n    log_reg_classifier.fit(x_train, y_train)\n    prediction = log_reg_classifier.predict(x_test)\n    accuracy = log_reg_classifier.score(x_train, y_train)\n    cm.append(confusion_matrix(y_test, prediction))\n    dfx = getTable(cm, 1)\n\n    print(\"\\nQ3:\")\n    print('Implement a Logistic regression classifier:')\n    print('The accuracy is', accuracy)\n    print(cm[1])\n    print(dfx)\n\n    # 4. Use Decision Tree\n    clf = tree.DecisionTreeClassifier(criterion='entropy')\n    clf = clf.fit(x_train, y_train)\n    prediction = clf.predict(x_test)\n    accuracy = accuracy_score(y_test, prediction)\n    cm.append(confusion_matrix(y_test, prediction))\n    dfx = getTable(cm, 2)\n\n    print(\"\\nQ4:\")\n    print('Implement a Decision Tree:')\n    print('The accuracy is', accuracy)\n    print('Confusion matrix:')\n    print(cm[2])\n    print(dfx)\n\n    # 5. Use Random Forest classifier\n    error_rate = []\n    random_forest_table = pd.DataFrame(columns=['n_estimators', 'max_depth', 'accuracy'])\n    for i in range(1, 11):\n        for j in range(1, 6):\n            rf = RandomForestClassifier(n_estimators=i, max_depth=j)\n            rf.fit(x_train, y_train)\n            error_rate.append(1 - accuracy_score(y_test, rf.predict(x_test)))\n            ACC = accuracy_score(y_test, rf.predict(x_test))\n            random_forest_table.loc[len(random_forest_table.index)] = [i, j, ACC]\n\n    # plot the error rate\n    plt.plot(range(1, 11), error_rate[:10], label=\"max_depth=1\")\n    plt.plot(range(1, 11), error_rate[10:20], label=\"max_depth=2\")\n    plt.plot(range(1, 11), error_rate[20:30], label=\"max_depth=3\")\n    plt.plot(range(1, 11), error_rate[30:40], label=\"max_depth=4\")\n    plt.plot(range(1, 11), error_rate[40:50], label=\"max_depth=5\")\n    plt.legend()\n    plt.xlabel(\"n_estimators\")\n    plt.ylabel(\"error rate\")\n    #plt.show()\n\n    best_n = error_rate.index(min(error_rate)) % 10 + 1\n    best_max = error_rate.index(min(error_rate)) % 5 + 1\n\n    print(\"\\nQ5:\")\n    print('Implement a Random Forest classifier :')\n    print(\"The best n_estimators and max_depth are\", best_n, \"and\", best_max)\n\n    rf = RandomForestClassifier(n_estimators=best_n, max_depth=best_max)\n    rf.fit(x_train, y_train)\n    cm.append(confusion_matrix(y_test, rf.predict(x_test)))\n    dfx = getTable(cm, 3)\n    accuracy = accuracy_score(y_test, rf.predict(x_test))\n\n    print('The accuracy is', accuracy)\n    print('Confusion matrix:')\n    print(cm[3])\n    print(dfx)\n\n    # 6. Use SVM classifier (linear, poly degree 2 and Gaussian)\n    for i in range(4, 7):\n        if i == 4:\n            # linear SVM.\n            svm_classifier = svm.SVC(kernel='linear')\n            kern = 'linear'\n        elif i == 5:\n            # Gaussian SVM\n            svm_classifier = svm.SVC(kernel='rbf')\n            kern = 'Gaussian'\n        else:\n            # SVM degree 2\n            svm_classifier = svm.SVC(kernel='poly', degree=2)\n            kern = 'polynomial'\n\n        svm_classifier.fit(x_train, y_train)\n        predicted = svm_classifier.predict(x_test)\n        accuracy = svm_classifier.score(x_test, y_test)\n        cm.append(confusion_matrix(y_test, predicted))\n        dfx = getTable(cm, i)\n\n        print('\\nQ6 - Task', i-3, ':')\n        print('Implement a', kern, 'SVM:')\n        print('The accuracy is', accuracy)\n        print('Confusion matrix is:')\n        print(cm[i])\n        print(dfx)\n\n    # 7. Summarize your results for Naive Bayesian, decision tree and random forest in a\n    # table below and discuss your findings.\n\n    for i in range(7):\n        TP, FP, FN, TN, ACC, TPR, TNR = getTable(cm, i, True)\n        new = [method[i], TP, FP, FN, TN, ACC, TPR, TNR]\n        result_table = result_table.append(pd.Series(new, index=result_table.columns[:len(new)]), ignore_index=True)\n\n    print('\\nQ7:')\n    print(result_table)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Q2_Q7()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}